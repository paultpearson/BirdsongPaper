{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Scalograms from Birdsong Samples, February 28, 2019\n",
    "\n",
    "This notebook contains code for converting WAV files into scalograms, as described in the book chapter \"Using Neural Networks to Identify Bird Species from Birdsong Samples\" by Russell Houpt, Mark Pearson, Paul Pearson, Taylor Rink, Sarah Seckler, Darin Stephenson, and Allison VanderStoep. This work was done at Hope College between 2016 and 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading some helpful packages and options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "from IPython.display import Audio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from matplotlib import patches\n",
    "matplotlib.style.use('grayscale')\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress = True, precision = 8)\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "font = {'family' : 'sans','weight' : 'normal','size'   : 12}\n",
    "plt.rc('axes', facecolor='white', edgecolor='black',grid=False)\n",
    "plt.rc('font', **font)\n",
    "\n",
    "import time\n",
    "import re\n",
    "import h5py\n",
    "saveDirectory = '/home/stephenson/Documents/birdsongs/Publication Notebooks/' #Change to a directory where the user has write permission.\n",
    "imageDirectory = saveDirectory+'images/'            #Create this subdirectory if needed.\n",
    "wavDirectory = '/data/BirdData/TrainingSet/wav/' #Location of the WAV data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>scalelist</b> is a function function that returns a list of \n",
    "scales given the num_scales (the number of scales), dj (the \n",
    "reciprocal of the number of scales per octave), and mi (a \n",
    "parameter controlling the minimum scale).\n",
    "\n",
    "<b>Morlet_scales</b> is a function that, given a list of scales, \n",
    "computes a dictionary containing th evectors defined by the \n",
    "Morlet wavelet at the points relevant for those scales. We divide\n",
    "each Morlet vector by the scale to allow for comparability of \n",
    "power across scales. The Morlet wavelet takes one parameter, \n",
    "$\\omega_0$, which controls the oscillation frequency of the base \n",
    "wavelet.\n",
    "\n",
    "The <b>maxpool_scalogram</b> function will 'maxpool' a scalogram\n",
    "by keeping only the maximum value across each non-overlapping \n",
    "horizontal set of pixels of size $c$. This takes an image that is\n",
    "$N$ pixels wide and returns an image that is (approximately) $N/C$\n",
    "pixels wide.\n",
    "\n",
    "<b>make_scalogram</b> is the main function to create scalograms\n",
    "from WAV files. The result is based on a list of scales, a \n",
    "dictionary containing the necessary wavelets at those scales, and\n",
    "a level of pooling. If a WAV file falls under min_time (in seconds),\n",
    "it will be replicated enough times until it is above min_time.\n",
    "\n",
    "<b>display_scalogram</b> contains tools for viewing a scalogram\n",
    "as an image, viewing column or row sums, and viewing a histogram\n",
    "of all power values in a scalogram. The parameters tmin and tmax\n",
    "control the minimum and maximum time index for viewing in horizontal\n",
    "pixels. (In an unpooled scalogram, typically 1 pixel corresponds\n",
    "to $1/44100$ seconds. The parameteris smin and smax control the\n",
    "minimum and maximum scale index (the vertical axis of the viewing\n",
    "window).\n",
    "\n",
    "<b>display_wav</b> will display the data in a WAV file as a time\n",
    "series between time indices tmin and tmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalelist(num_scales = 64, dj = 0.125,mi = 3):\n",
    "    return 2 ** (1+dj * np.arange(mi, num_scales+mi))\n",
    "\n",
    "def Morlet_scales(scales,omega0=8.0):\n",
    "    d = {}\n",
    "    for scale in scales:\n",
    "        M = int(1+2*np.around((10*scale-1)/2))\n",
    "        tt = np.arange( (-M+1.0)/2.0, (M+1.0)/2.0 ) \n",
    "        x = tt / scale\n",
    "        psi_Morlet  = np.exp(1j * omega0 * x) \n",
    "        psi_Morlet -= np.exp(-0.5 * (omega0)**2)\n",
    "        psi_Morlet *= np.exp(-0.5 * (x**2)) * np.pi**(-0.25)\n",
    "        psi_Morlet /= scale \n",
    "        d[scale] = psi_Morlet\n",
    "    return d\n",
    "\n",
    "def maxpool_scalogram(scalogram,c=1):\n",
    "    maxpooled_scalogram_length = len(scalogram[1])\n",
    "    cut = np.arange(0, maxpooled_scalogram_length, c)\n",
    "    new_scalogram = np.maximum.reduceat(scalogram, cut, axis = 1)\n",
    "    return new_scalogram\n",
    "\n",
    "def make_scalogram(filename,scales,Morlet_dict,pooling=1,min_time=4):\n",
    "    samplerate, s = wav.read(filename)\n",
    "    s_length = len(s)\n",
    "    while len(s) < min_time*44100:\n",
    "        s = np.append(s,s)\n",
    "        s_length = len(s)\n",
    "    s = np.array(s)\n",
    "    scalogram = np.zeros( (len(scales), s_length), dtype=np.complex)\n",
    "    for ind, scale in enumerate(scales):\n",
    "        scalogram[ind,:] = signal.fftconvolve(s, Morlet_dict[scale], mode='same')\n",
    "    power = (np.absolute(scalogram))**2\n",
    "    if pooling > 1:\n",
    "        power = maxpool_scalogram(power,c=pooling)\n",
    "    power /= np.max(power)\n",
    "    return power\n",
    "\n",
    "\n",
    "def display_scalogram(scal,tmin=0,tmax=-1,smin=0,smax=-1,savefig=False,\n",
    "                      filename='output',colormap = 'Greys',lum=1,\n",
    "                      display=True,disp_row=False,disp_col=False,disp_wav=False,\n",
    "                     disp_hist=False,bins=100):\n",
    "    plt.figure(figsize =(20,8))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(scal[smin:smax,tmin:tmax], \n",
    "               vmin = 0,vmax = 1/lum,\n",
    "               aspect='auto', cmap=colormap)\n",
    "    if savefig:\n",
    "        plt.savefig(filename+\"-scalogram.png\",dpi='figure')\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    if disp_row:\n",
    "        plt.figure(figsize =(20,8))\n",
    "        plt.grid(False)\n",
    "        plt.plot(np.sum(scal[smin:smax,tmin:tmax],axis=0))\n",
    "        if savefig:\n",
    "            plt.savefig(filename+\"-rowsums.png\",dpi='figure')\n",
    "        plt.show()\n",
    "    if disp_col:\n",
    "        plt.figure(figsize =(20,8))\n",
    "        plt.grid(False)\n",
    "        plt.plot(np.sum(scal[smin:smax,tmin:tmax],axis=1))\n",
    "        if savefig:\n",
    "            plt.savefig(filename+\"-columnsums.png\",dpi='figure')\n",
    "        plt.show()\n",
    "    if disp_hist:\n",
    "        plt.figure(figsize=(20,8))\n",
    "        plt.grid(False)\n",
    "        plt.hist(scal.reshape(-1,),bins=bins)\n",
    "        if savefig:\n",
    "            plt.savefig(filename+\"-histogram.png\",dpi='figure')\n",
    "        plt.show()\n",
    "        \n",
    "def display_wav(filename,tmin=0,tmax=-1,loop=True,min_time=4):\n",
    "    samplerate, s = wav.read(filename)\n",
    "    if loop:\n",
    "        while len(s) < min_time*44100:\n",
    "            s = np.append(s,s)\n",
    "            s_length = len(s)\n",
    "    plt.figure(figsize =(20,8))\n",
    "    plt.grid(False)\n",
    "    plt.plot(s[tmin:tmax])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a pandas dataframe from a CSV file containing filenames\n",
    "for each WAV file, along with a file id number, the correct\n",
    "species name, the length of the WAV vector (in the samples column),\n",
    "and the length of the WAV recording in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fileListdf.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we choose the species to work with and define a\n",
    "slice of the overall dataframe related to those species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesList = [\"Bananaquit\",\"Roadside Hawk\",\"Green Violetear\",\"Buff-breasted Wren\"]\n",
    "df2 = df[df['name'].isin(speciesList)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell does the train/validation/test split. The final\n",
    "two lines can be used to check that each of the training and\n",
    "validation sets has adequate representation of WAV files from\n",
    "each species. The np.random.seed can be used to assure the same\n",
    "behavior of the np.random.choice commands on each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFrac = 0.60\n",
    "validFrac = 0.10\n",
    "np.random.seed(100)\n",
    "trainRows = np.sort(np.random.choice(np.arange(df2.shape[0]),replace=False,size=int(trainFrac*df2.shape[0])))\n",
    "remainingRows = np.array([x for x in np.arange(df2.shape[0]) if x not in trainRows])\n",
    "validRows = np.sort(np.random.choice(remainingRows,replace=False,size=int(validFrac*df2.shape[0])))\n",
    "testRows = np.array([x for x in remainingRows if x not in validRows])\n",
    "df_train = pd.DataFrame(df2.iloc[trainRows,:])\n",
    "df_valid = pd.DataFrame(df2.iloc[validRows,:])\n",
    "df_test = pd.DataFrame(df2.iloc[testRows,:])\n",
    "df_train.to_csv(\"traindf.csv\",index=False)\n",
    "df_valid.to_csv(\"validdf.csv\",index=False)\n",
    "df_test.to_csv(\"testdf.csv\",index=False)\n",
    "\n",
    "print([df_train[df_train.name == n].shape[0] for n in speciesList])\n",
    "print([df_valid[df_valid.name == n].shape[0] for n in speciesList])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change train_index below to see scalograms of different WAV files from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = 0\n",
    "scales = scalelist(mi=3,num_scales=64,dj=0.125)\n",
    "Morlet_dict = Morlet_scales(scales,omega0=8.0)\n",
    "P = make_scalogram(wavDirectory\n",
    "                   + df_train.values[train_index][1],scales=scales,\n",
    "                   Morlet_dict=Morlet_dict)\n",
    "display_scalogram(P,lum=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell generates scalograms for all WAV files in the data set for the chosen species. Additionally, the code averages scalograms that are in the training set for each species down onto the scale axis, and then stores this in the scaleTotals array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_species = len(speciesList)\n",
    "spectrogram_maxpool_constant = 50\n",
    "num_scales = 64\n",
    "w0=8.0\n",
    "verbose = True\n",
    "saveAveragePlots = False\n",
    "\n",
    "t0 = time.time()\n",
    "bird_num = 0\n",
    "h5_file = h5py.File(saveDirectory+\"scalograms.hdf5\")\n",
    "scaleTotals = np.zeros([num_species,num_scales]).astype(float)\n",
    "scales = scalelist(mi=3,num_scales=num_scales,dj=0.125)\n",
    "Morlet_dict = Morlet_scales(scales,omega0=w0)\n",
    "for speciesName in speciesList:\n",
    "    df_single = df2[df2.name == speciesName][['id','filename','name']]\n",
    "    info = df_single.values \n",
    "    total = 0  \n",
    "    train_total = 0\n",
    "    for sample in info:  \n",
    "    # for testing on a small set -- for sample in info[0:8]:\n",
    "        total += 1\n",
    "        idn = sample[0]\n",
    "        path_to_file = wavDirectory + sample[1]\n",
    "        targetname = sample[2]\n",
    "        scal = make_scalogram(path_to_file,scales=scales,Morlet_dict=Morlet_dict,pooling=spectrogram_maxpool_constant)\n",
    "        if idn in df_train.id.values: \n",
    "            C = np.sum(scal,axis=1)\n",
    "            C /= C.max()\n",
    "            scaleTotals[bird_num] += C\n",
    "            train_total += 1\n",
    "        dset = h5_file.create_dataset(str(idn), (num_scales,scal.shape[1]), dtype='float64',data=scal)\n",
    "        dset.attrs['speciesName'] = speciesName\n",
    "        dset.attrs['fileid'] = idn\n",
    "        dset.attrs['size']=[num_scales,scal.shape[1]]\n",
    "        if verbose:\n",
    "            print(speciesName,total,\"out of\",df_single.shape[0],\"; Elapsed:\",time.time()-t0)\n",
    "    scaleTotals[bird_num] /= train_total\n",
    "    plt.plot(scaleTotals[bird_num])\n",
    "    plt.title(speciesName+\" Averages\")\n",
    "    if saveAveragePlots:\n",
    "        plt.savefig(imageDirectory+speciesName+\"-averages.png\")\n",
    "    plt.show()\n",
    "    bird_num += 1\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will create \"snippets\" of a given length from each scalogram. Our default is to segment the scalogram into 1.5 second snippets. These snippets start every 0.25 seconds, so that there is a 1.25 second overlap between successive snippets. For each scalogram, a percentage of the snippets is chosen to retain. The process below retains the top (100-pctScore) percent of the snippets by total power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displayScalogram = False\n",
    "displaySnippets = False\n",
    "saveSnippets = True\n",
    "num_species = len(speciesList)\n",
    "spectrogram_maxpool_constant = 50\n",
    "num_scales = 64\n",
    "date = 'Feb-27-2019'\n",
    "pctScore = 50\n",
    "\n",
    "h5_file_in = h5py.File(saveDirectory+\"scalograms.hdf5\", \"a\")\n",
    "\n",
    "if saveSnippets:\n",
    "    h5_file_out = h5py.File(saveDirectory+\"snippets.hdf5\", \"a\")\n",
    "for speciesName in speciesList:\n",
    "    df_single = df2[df2.name == speciesName][['id','filename','name']]\n",
    "    info = df_single.values \n",
    "    total = 0\n",
    "    for sample in info:\n",
    "    # for testing on a small set -- for sample in info[0:8]:\n",
    "        total += 1\n",
    "        idn = sample[0]\n",
    "        fileId = sample[1]\n",
    "        targetname = sample[2]\n",
    "        scal = np.array(h5_file_in[str(idn)])\n",
    "        if displayScalogram:\n",
    "            display_scalogram(scal)\n",
    "        fraction = 0.25 #Step by 0.25 seconds\n",
    "        one_sec = int(44100/spectrogram_maxpool_constant)\n",
    "        step_length = int(fraction*one_sec)\n",
    "        frame_length = int(1.5*one_sec)\n",
    "        frames = 1+int((scal.shape[1]-frame_length)/step_length)\n",
    "        powerTotals = np.zeros([frames]).astype(float)\n",
    "        for j in range(frames):\n",
    "            powerTotals[j] = np.mean(scal[:,j*step_length:j*step_length+frame_length])\n",
    "        cutoff = np.percentile(powerTotals,pctScore)\n",
    "        keep_frames = 0\n",
    "        for j in range(frames):\n",
    "            scal_snip = np.copy(scal[:,j*step_length:j*step_length+frame_length])\n",
    "            d = np.mean(scal_snip)\n",
    "            if  d >= cutoff:   \n",
    "                C = np.copy(scal[:,j*step_length:j*step_length+frame_length])\n",
    "                if displaySnippets:\n",
    "                    plt.grid(False)\n",
    "                    plt.title(str(targetname),loc = 'left')\n",
    "                    plt.title(re.search('RN(.*).wav',fileId).group(1))\n",
    "                    plt.imshow(C, aspect='auto', cmap='Greys')\n",
    "                    plt.show()\n",
    "                if saveSnippets:\n",
    "                    dset = h5_file_out.create_dataset(str(idn)+'-'+str(keep_frames), (num_scales,1323), dtype='float64',data=C)\n",
    "                    dset.attrs['speciesName'] = speciesName\n",
    "                    dset.attrs['sniplength'] = 1.5\n",
    "                    dset.attrs['fileid'] = idn\n",
    "                    dset.attrs['size']=[num_scales,1323]\n",
    "                keep_frames += 1\n",
    "        print(speciesName,idn,\":\",total,'out of',df_single.shape[0],\"; Frames:\",keep_frames,\"/\",frames)\n",
    "if saveSnippets:\n",
    "    h5_file_out.close()     \n",
    "h5_file_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a list of the 100 birds we used at the end of Summer 2017.\n",
    "\n",
    "# speciesList = [\"Bananaquit\",\"Roadside Hawk\",\"Green Violetear\",\"Buff-breasted Wren\",\n",
    "#             \"Southern Beardless Tyrannulet\",\"Rufous-browed Peppershrike\",\n",
    "#             \"Grey-breasted Wood Wren\", \"Rufous-collared Sparrow\", \"House Wren\", \n",
    "#             \"Apolinar's Wren\", \"Blackish Tapaculo\", \"Plain Antvireo\", \n",
    "#             \"Great Kiskadee\", \"Barred Forest Falcon\", \"Niceforo's Wren\", \n",
    "#             \"Golden-crowned Warbler\", \"Whiskered Wren\", \"Long-billed Gnatwren\", \n",
    "#             \"Little Tinamou\", \"Blue Manakin\", \"Pale-bellied Tapaculo\", \n",
    "#             \"Cinereous Tinamou\", \"Tyrian Metaltail\", \"Yellow-olive Flatbill\", \n",
    "#             \"Pauraque\", \"Olivaceous Woodcreeper\", \"Rufous-bellied Thrush\", \n",
    "#             \"Channel-billed Toucan\", \"Long-billed Wren\", \"Pale-breasted Thrush\", \n",
    "#             \"Southern Lapwing\", \"Sparkling Violetear\", \"Chestnut Wood Quail\", \n",
    "#             \"Buff-throated Woodcreeper\", \"Tropical Screech Owl\", \n",
    "#             \"Rufous-tailed Jacamar\", \"Munchique Wood Wren\", \n",
    "#             \"Pale-breasted Spinetail\", \"Spillmann's Tapaculo\", \"Plumbeous Pigeon\",\n",
    "#             \"Chestnut-breasted Wren\", \"Squirrel Cuckoo\", \"Golden-fronted Whitestart\", \n",
    "#             \"Yellow-legged Thrush\", \"Screaming Piha\", \"White-throated Toucan\", \n",
    "#             \"Yellow-headed Caracara\", \"Black-crested Antshrike\", \n",
    "#             \"Colombian Mountain Grackle\", \"White-shouldered Fire-eye\", \n",
    "#             \"White-bearded Manakin\", \"Red-eyed Vireo\", \"Azara's Spinetail\", \n",
    "#             \"Tropical Mockingbird\", \"Slaty-crowned Antpitta\", \"Boat-billed Flycatcher\", \n",
    "#             \"Tropical Parula\", \"Great Antshrike\", \"Common Bush Tanager\", \n",
    "#             \"Blue-backed Manakin\",\"Parker's Antbird\", \"Golden-faced Tyrannulet\", \n",
    "#             \"Striped Cuckoo\", \"Andean Guan\", \"Cundinamarca Antpitta\", \n",
    "#             \"Euler's Flycatcher\", \"Lineated Woodpecker\", \"Ochre-lored Flatbill\", \n",
    "#             \"Short-tailed Antthrush\", \"White-winged Becard\", \"Tropical Kingbird\", \n",
    "#             \"Russet-crowned Warbler\", \"Brown Tinamou\", \"Lesser Woodcreeper\", \n",
    "#             \"Green-winged Saltator\", \"Laughing Falcon\", \"Schwartz's Antthrush\", \n",
    "#             \"Yellow-bellied Elaenia\", \"Rufous-winged Antwren\", \"Yellow-chinned Spinetail\", \n",
    "#             \"Piratic Flycatcher\", \"Smooth-billed Ani\", \"White-eyed Foliage-gleaner\", \n",
    "#             \"Yellow-bellied Seedeater\", \"Green-backed Trogon\", \"Barred Antshrike\", \n",
    "#             \"Ferruginous Pygmy Owl\", \"Southern Nightingale-Wren\", \"Giant Antshrike\", \n",
    "#             \"Squamate Antbird\", \"Streaked Flycatcher\", \"Northern Mountain Cacique\", \n",
    "#             \"Grey-hooded Attila\", \"Chestnut-crowned Antpitta\", \"Sedge Wren\", \n",
    "#             \"Black-throated Antbird\", \"Black Hawk-Eagle\", \"Red-throated Caracara\", \n",
    "#             \"Rufous-capped Spinetail\", \"Inca Jay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the process below, we can visualize which snippets are kept and discarded for a given scalogram. Adjust <b>species_for_plotting</b>, <b>index_min</b>, and <b>index_max</b> to control which scalograms are considered. The heavy horizontal line on the scalogram represents the average power below which snippets were discarded. The other curve plots the average power of each snippet based on the time parameter in the WAV file. The <b>pctScore</b> is the percentage of snippets that are discarded, and can be adjusted to move the horizontal line up and down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pctScore = 50\n",
    "spectrogram_maxpool_constant = 50\n",
    "num_scales = 64\n",
    "\n",
    "species_for_plotting = speciesList\n",
    "index_min = 0\n",
    "index_max = 1\n",
    "\n",
    "h5_file_in = h5py.File(saveDirectory+\"scalograms.hdf5\", \"a\")\n",
    "for speciesName in species_for_plotting:\n",
    "    df_single = df_train[df_train.name == speciesName][['id','filename','name']]\n",
    "    info = df_single.values \n",
    "    total = 0\n",
    "    for sample in info[index_min:index_max+1]:\n",
    "        total += 1\n",
    "        idn = sample[0]\n",
    "        fileId = sample[1]\n",
    "        targetname = sample[2]\n",
    "        scal = np.array(h5_file_in[str(idn)])\n",
    "        fraction = 0.25 #Step by 0.25 seconds\n",
    "        one_sec = int(44100/spectrogram_maxpool_constant)\n",
    "        step_length = int(fraction*one_sec)\n",
    "        frame_length = int(1.5*one_sec)\n",
    "        frames = 1+int((scal.shape[1]-frame_length)/step_length)\n",
    "        powerTotals = np.zeros([frames]).astype(float)\n",
    "        for j in range(frames):\n",
    "            powerTotals[j] = np.mean(scal[:,j*step_length:j*step_length+frame_length])\n",
    "        cutoff = np.percentile(powerTotals,pctScore)\n",
    "        t = [(m+3)*220.5 for m in range(frames)]\n",
    "        plt.figure(figsize =(20,8))\n",
    "        plt.grid(False)\n",
    "        plt.imshow(scal,vmin = 0,vmax = 0.3,aspect='auto', cmap='Greys')\n",
    "        plt.plot(t,60-powerTotals/np.max(powerTotals)*40,color='blue')\n",
    "        plt.plot(t,[60-cutoff/np.max(powerTotals)*40]*len(t),color='blue',linewidth=3)\n",
    "        plt.show()\n",
    "h5_file_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
